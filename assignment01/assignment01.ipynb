{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 1\n",
    "\n",
    "### To be submitted before 30 May 2020.\n",
    "\n",
    "An short introduction about PyTorch and about the chosen functions. \n",
    "- torch.index_select()\n",
    "- torch.eq()\n",
    "- torch.dot()\n",
    "- torch.fmod()\n",
    "- torch.inverse()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import torch and other required modules\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function 1 - torch.index_select()\n",
    "\n",
    "torch.index_select(input, dim, index, out=None) --> Tensor\n",
    "\n",
    "index_select is a function that returns a new tensor which has the entries specified in index of the tensor defined in input.\n",
    "\n",
    "It has the same number of dimension as the original tensor (defined in input). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.7081, -0.1952,  0.1616, -0.6794],\n",
       "        [ 0.2017, -2.0601,  0.4825,  0.0657],\n",
       "        [ 1.2947,  0.5529, -0.4297, -0.1562],\n",
       "        [-0.6232,  1.1203, -0.7710,  0.1843],\n",
       "        [-0.3766,  0.0581, -1.6676, -0.6237]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example 1\n",
    "#create x using randn with 5 rows and 4 columns\n",
    "x = torch.randn(5, 4)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 2])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#choose the entries you'd like to see in the new tensor\n",
    "index = torch.tensor([0,2])\n",
    "index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.7081,  0.1616],\n",
       "        [ 0.2017,  0.4825],\n",
       "        [ 1.2947, -0.4297],\n",
       "        [-0.6232, -0.7710],\n",
       "        [-0.3766, -1.6676]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#define a dim from -2, -1, 0, 1 where dim -1 = dim 1, dim -2 = dim 0\n",
    "#dim = 1 => entries 0, 2 column wise\n",
    "\n",
    "torch.index_select(x, 1, index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.7081, -0.1952,  0.1616, -0.6794],\n",
       "        [ 1.2947,  0.5529, -0.4297, -0.1562]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#if you change the dim to 0, then you'll see that it'll be entry 0, 2 row wise\n",
    "\n",
    "torch.index_select(x, 0, index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the tensor x - created in the beginning - was a rank 2 tensor and had 2 dimensions (dim = 0 and dim = 1), that's what the new tensors created from the function index_select() would have too. \n",
    "The above example demostrates how you can create new tensors from entries of another. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.5172, -0.5266, -1.5842, -0.8504],\n",
       "         [-1.7954,  0.6498, -0.5670, -0.1746],\n",
       "         [-0.5155, -1.1931,  1.7387, -1.6547]],\n",
       "\n",
       "        [[ 1.0430, -0.1878, -0.8700,  0.9095],\n",
       "         [ 1.5274, -1.5575,  0.0954, -1.3150],\n",
       "         [ 0.4056, -1.1424,  1.0748, -0.9034]],\n",
       "\n",
       "        [[-0.4914, -0.8851,  1.1622,  0.3159],\n",
       "         [ 1.2296, -1.2334,  0.3211, -1.5192],\n",
       "         [-1.2191,  1.7833,  0.4993, -1.1859]]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example 2 \n",
    "#create a 3 dimentional tensor\n",
    "y = torch.randn(3, 3, 4)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 1])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#define the entries you'd want in your new tensor\n",
    "indices = torch.tensor([0,1])\n",
    "indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.5172, -0.5266, -1.5842, -0.8504],\n",
       "         [-1.7954,  0.6498, -0.5670, -0.1746],\n",
       "         [-0.5155, -1.1931,  1.7387, -1.6547]],\n",
       "\n",
       "        [[ 1.0430, -0.1878, -0.8700,  0.9095],\n",
       "         [ 1.5274, -1.5575,  0.0954, -1.3150],\n",
       "         [ 0.4056, -1.1424,  1.0748, -0.9034]]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#define a dimention \n",
    "#as dim = 0 is associated with rows, and based on the index defined, all tensor remain unchanged\n",
    "torch.index_select(y, 0, indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.5172, -0.5266],\n",
       "         [-1.7954,  0.6498],\n",
       "         [-0.5155, -1.1931]],\n",
       "\n",
       "        [[ 1.0430, -0.1878],\n",
       "         [ 1.5274, -1.5575],\n",
       "         [ 0.4056, -1.1424]],\n",
       "\n",
       "        [[-0.4914, -0.8851],\n",
       "         [ 1.2296, -1.2334],\n",
       "         [-1.2191,  1.7833]]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#try with dim = 2\n",
    "\n",
    "torch.index_select(y, 2, indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.5172, -0.5266, -1.5842, -0.8504],\n",
       "         [-0.5155, -1.1931,  1.7387, -1.6547]],\n",
       "\n",
       "        [[ 1.0430, -0.1878, -0.8700,  0.9095],\n",
       "         [ 0.4056, -1.1424,  1.0748, -0.9034]],\n",
       "\n",
       "        [[-0.4914, -0.8851,  1.1622,  0.3159],\n",
       "         [-1.2191,  1.7833,  0.4993, -1.1859]]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.index_select(y, 1, index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The example above demonstracts the creation of a 3 dimentional tensor from another 3 dimentional tenor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.7951, -1.2985, -0.9913, -0.3244],\n",
       "        [ 0.6757,  0.7724, -0.0403,  0.1759],\n",
       "        [ 0.6167,  1.2116, -0.3453, -0.7736]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example 3 - breaking (to illustrate when it breaks)\n",
    "z = torch.randn(3, 4)\n",
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index = torch.tensor(3)\n",
    "index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index out of range in self",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-b0c760430773>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex_select\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m: index out of range in self"
     ]
    }
   ],
   "source": [
    "torch.index_select(z, 0, index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the example above, we chose dimension to be 0, which is looking at the tensor row wise. As you can see there is no row with index 3. Its range is [0,2].\n",
    "Note that, if we took dimenstion to be 1, which is looking at it column wise, then it would've worked. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inde = torch.tensor(2)\n",
    "inde"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "Dimension out of range (expected to be in range of [-2, 1], but got 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-5f1527847d9c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex_select\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minde\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m: Dimension out of range (expected to be in range of [-2, 1], but got 2)"
     ]
    }
   ],
   "source": [
    "torch.index_select(z, 2, inde)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The example above demostrates the invalid input of dimension. Since it only has 2 (0 and 1), so it doesn't span 2. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function really triggered an interest in me because of the way it dealt with dimensions. I took my time to see how the entries were extracted when dimension varied. The resource that really helped me understanding dimensions and helped me visualise this is an article written by Aerin Kim- that can be found here: https://medium.com/@aerinykim/numpy-sum-axis-intuition-6eb94926a5d1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function 2 - torch.eq()\n",
    "\n",
    "torch.eq(input, other, out=None) --> Tensor\n",
    "\n",
    "This function examines two tensors element by element and check if they are equal. \n",
    "\n",
    "It returns a tensor but the elements are either 'True' or 'False'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[False, False],\n",
       "        [ True,  True],\n",
       "        [ True,  True]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example 1 \n",
    "\n",
    "x = torch.tensor([[1,2], [3,4], [5,6]])\n",
    "\n",
    "y = torch.tensor([[2,1], [3,4], [5,6]])\n",
    "\n",
    "torch.eq(x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The example above demonstrates the comparsion of the two tensors taking place. So what the function is doing is comparing the tensore element wise. As 1 does not equal 2, the output is False. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[False, False],\n",
       "        [False, False],\n",
       "        [False, False]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example 2 \n",
    "x = torch.tensor([[1,2], [3,4], [5,6]])\n",
    "\n",
    "z = torch.tensor([[2,1], [5,6], [3,4]])\n",
    "\n",
    "torch.eq(x, z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above example indicates that the position matters. All I did for z was change the position of the second and third component of y and the output is very different to example 1. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(True)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example 3 \n",
    "x = torch.tensor([[1,2], [3,4], [5,6]])\n",
    "\n",
    "torch.eq(torch.tensor(x.dim()), 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example 3 shows that the function isn't just useful to compare tensors. You can also check the number of dimensions are the same. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "eq() received an invalid combination of arguments - got (Tensor, str), but expected one of:\n * (Tensor input, Tensor other, *, Tensor out)\n * (Tensor input, Number other, *, Tensor out)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-6cfe443a96fa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'a'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: eq() received an invalid combination of arguments - got (Tensor, str), but expected one of:\n * (Tensor input, Tensor other, *, Tensor out)\n * (Tensor input, Number other, *, Tensor out)\n"
     ]
    }
   ],
   "source": [
    "# Example 4 - breaking (to illustrate when it breaks)\n",
    "\n",
    "x = torch.tensor([[1,2], [3,4], [5,6]])\n",
    "\n",
    "torch.eq(x, 'a')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above example shows that you would only be able to compare tensors to a numerical value and not a string. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function torch.eq() interested me because if we had a large dataset, this will help us reduce it by checking if there are any of the same included. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function 3 - torch.dot()\n",
    "\n",
    "torch.dot(input, tensor) --> Tensor\n",
    "\n",
    "This function computes the dot product of the two tensors. \n",
    "\n",
    "It only accepts one dimensional tensors (rank 1) as they take the form of vectors. \n",
    "\n",
    "This returns a tensor of rank 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(11)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example 1\n",
    "x = torch.tensor([3,4])\n",
    "\n",
    "y = torch.tensor([1,2])\n",
    "\n",
    "torch.dot(x,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What the above is doing is ((3x1) + (4x2)) = 11. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(128)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example 2\n",
    "m = torch.tensor([3,4, 5, 6, 7, 8])\n",
    "\n",
    "n = torch.tensor([1,2, 7, 5, 4, 3])\n",
    "\n",
    "torch.dot(m, n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example two is just a bigger tensor (vector). (3x1)+(4x2)+(5x7)+(6x5)+(7x4)+(8x3) = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "1D tensors expected, got 3D, 3D tensors at /opt/conda/conda-bld/pytorch_1587428266983/work/aten/src/TH/generic/THTensorEvenMoreMath.cpp:431",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-fcf431f0ac3f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m: 1D tensors expected, got 3D, 3D tensors at /opt/conda/conda-bld/pytorch_1587428266983/work/aten/src/TH/generic/THTensorEvenMoreMath.cpp:431"
     ]
    }
   ],
   "source": [
    "# Example 3 - breaking\n",
    "\n",
    "c = torch.randn(2,2,2)\n",
    "\n",
    "v = torch.randn(2,2,2)\n",
    "\n",
    "print(torch.dot(c,v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "1D tensors expected, got 2D, 2D tensors at /opt/conda/conda-bld/pytorch_1587428266983/work/aten/src/TH/generic/THTensorEvenMoreMath.cpp:431",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-2713bfcfeccc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mq\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m: 1D tensors expected, got 2D, 2D tensors at /opt/conda/conda-bld/pytorch_1587428266983/work/aten/src/TH/generic/THTensorEvenMoreMath.cpp:431"
     ]
    }
   ],
   "source": [
    "q = torch.randn(2,2)\n",
    "\n",
    "p = torch.randn(2,2)\n",
    "\n",
    "print(torch.dot(q,p))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To help visualise why these aren't working, dot product only feasible with vectors (which are 1D tensors). Not possible with matrices and 3D tensors. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "torch.dot function was an interesting one to look at because it can get long to compute it manually. This functions gives people opportunity to spend less time on it.  \n",
    "\n",
    "Dot products are useful for finding angles between 2 vectors or straight lines or angles between intersecting planes. It has many use cases."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function 4 - torch.fmod()\n",
    "\n",
    "fmod(input, divisor, out=None) --> Tensor\n",
    "\n",
    "This function computes the remainder of division element wise.\n",
    "\n",
    "The tensor given as input must compose of either integers or floating points.\n",
    "\n",
    "The divisor can be a tensor but it must match the size of the tensor given as input. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.2517, -0.3057,  2.7854,  0.1773,  0.7291],\n",
       "        [ 1.3509,  0.0454, -0.0231, -0.4075,  0.3394]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example 1 \n",
    "x = torch.randn(2,5)\n",
    "\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.2517, -0.3057,  0.2854,  0.1773,  0.2291],\n",
       "        [ 0.3509,  0.0454, -0.0231, -0.4075,  0.3394]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.fmod(x, 0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above example shows the generation of a new tensor based on the remainder of x when divided by 0.5. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.5806,  0.9117, -1.5203,  2.0758,  0.8727],\n",
       "        [ 1.5655,  0.8079,  0.3066,  2.1633, -0.0402]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example 2 \n",
    "\n",
    "y = torch.randn(2,5)\n",
    "\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.1591,  1.7832, -0.9690, -0.6447, -1.3046],\n",
       "        [ 0.5104, -0.7494,  0.3865,  0.8877,  1.4321]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "div = torch.randn(2,5)\n",
    "\n",
    "div"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.1484,  0.9117, -0.5512,  0.1419,  0.8727],\n",
       "        [ 0.0342,  0.0585,  0.3066,  0.3878, -0.0402]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.fmod(y, div)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example 2 demonstrates how you can divide tensors by tensors of the same size. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 2.0507, -0.1698, -0.7410, -0.9489, -0.4494],\n",
       "        [ 0.2283,  0.8712,  0.7189,  0.4397,  0.9827]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example 3 - breaking (to illustrate when it breaks)\n",
    "\n",
    "z = torch.randn(2,5)\n",
    "\n",
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.6306,  0.1019,  0.7398]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "divn = torch.randn(1,3)\n",
    "\n",
    "divn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (5) must match the size of tensor b (3) at non-singleton dimension 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-c3ff305c5c4d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfmod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdivn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (5) must match the size of tensor b (3) at non-singleton dimension 1"
     ]
    }
   ],
   "source": [
    "torch.fmod(z, divn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example 3 shows that the two tensors must match the size otherwise, it'll throw an error as above"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function torch.fmod intriguing because maths made simple always makes me a fan!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function 5 - torch.inverse()\n",
    "\n",
    "inverse(input, out=None) --> Tensor\n",
    "\n",
    "This function takes the inverse of a given square matrix. These matraices can be batches of 2D square tensors to which a tensor compose of individual inverses is returned. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.5421, -0.5602,  3.3080, -0.6643],\n",
       "        [-0.1791,  0.5164,  0.9068, -0.9018],\n",
       "        [-1.0950,  0.0482, -0.7268,  0.8043],\n",
       "        [ 0.6360, -1.0838,  0.3234,  0.2340]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example 1\n",
    "\n",
    "x = torch.randn(4,4)\n",
    "\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.1912, -1.2689, -1.0466, -0.7500],\n",
       "        [ 0.3957, -1.3085, -0.6229, -1.7784],\n",
       "        [ 0.4710, -0.4213,  0.0453, -0.4422],\n",
       "        [ 0.6622, -2.0298, -0.1033, -1.3141]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = torch.inverse(x)\n",
    "\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This example shows that we inversed a 4 by 4 matrix. y is the inverse of x. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-1.7502,  0.3364, -0.1802],\n",
       "         [-1.2338, -2.7713,  0.3425],\n",
       "         [-0.4743, -1.5426, -1.4060]],\n",
       "\n",
       "        [[ 0.3445,  0.4397,  0.0258],\n",
       "         [-0.1513,  1.1194,  1.7242],\n",
       "         [ 0.9152,  0.1835,  0.5815]]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example 2\n",
    "\n",
    "x = torch.randn(2, 3, 3)\n",
    "\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.5213, -0.0885,  0.0453],\n",
       "         [ 0.2235, -0.2798, -0.0968],\n",
       "         [-0.0694,  0.3369, -0.6203]],\n",
       "\n",
       "        [[ 0.4077, -0.3058,  0.8886],\n",
       "         [ 2.0302,  0.2153, -0.7286],\n",
       "         [-1.2822,  0.4133,  0.5510]]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = torch.inverse(x)\n",
    "\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The example above is of a 3D tensor where you have 2 3 by 3 tensors. How this works is, the inverse of each 3 by 3 tensor is worked out separately and combined in a new tensor, which is the output.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "A must be batches of square matrices, but they are 3 by 4 matrices",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-e5c9e2953178>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minverse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: A must be batches of square matrices, but they are 3 by 4 matrices"
     ]
    }
   ],
   "source": [
    "# Example 3 - breaking (to illustrate when it breaks)\n",
    "\n",
    "x = torch.randn(4,3)\n",
    "\n",
    "y = torch.inverse(x)\n",
    "\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The example above breaks because it's not a square matrix."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function torch.inverse looks at the inverse of rank 2 tensors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "To conclude the functions we looked at here are:\n",
    "torch.index_select - creating a tensor based on the index and dim defined \n",
    "torch.eq - creating a tensor with True or False outputs, based on element equality \n",
    "torch.dot - computing a scalar tensor using the dot product of vectors\n",
    "torch.fmod - computing a new tensor based on the remainder you get when you divide the defined tensor by the a defined divisor\n",
    "torch.inverse - computing the inverse of a square matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reference Links\n",
    "Provide links to your references and other interesting articles about tensors\n",
    "* Official documentation for `torch.Tensor`: https://pytorch.org/docs/stable/tensors.html\n",
    "* Article on dimensions: https://medium.com/@aerinykim/numpy-sum-axis-intuition-6eb94926a5d1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install jovian --upgrade --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jovian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "window.require && require([\"base/js/namespace\"],function(Jupyter){Jupyter.notebook.save_checkpoint()})"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[jovian] Attempting to save notebook..\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "jovian.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
